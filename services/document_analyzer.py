"""
–°–µ—Ä–≤–∏—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""

import json
import os
from typing import List
from document_processor import DocumentProcessor
from api.ollama_client import (
    call_ollama_api,
    call_ollama_api_with_images,
    call_ollama_api_with_pdf,
)
from utils.helpers import clean_json_response
from utils.helpers import PYMUPDF_AVAILABLE

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
doc_processor = DocumentProcessor(dpi=150, max_pages=30)


def analyze_document_with_pdf(file_path: str, gost_name: str) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —á–µ—Ä–µ–∑ –æ—Ç–ø—Ä–∞–≤–∫—É PDF —Ñ–∞–π–ª–∞ –Ω–∞–ø—Ä—è–º—É—é –≤ Ollama."""
    try:
        print(f"üìÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É PDF —Ñ–∞–π–ª–∞ –Ω–∞–ø—Ä—è–º—É—é: {file_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —ç—Ç–æ PDF
        file_ext = os.path.splitext(file_path)[1].lower()
        if file_ext != ".pdf":
            return {
                "success": False,
                "error": f"–§—É–Ω–∫—Ü–∏—è analyze_document_with_pdf –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ PDF —Ñ–∞–π–ª—ã, –ø–æ–ª—É—á–µ–Ω: {file_ext}",
            }

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞ –ø–æ –ì–û–°–¢—É
        if "7.32" in gost_name:
            return analyze_structure_from_pdf(file_path, gost_name)
        else:
            return analyze_bibliography_from_pdf(file_path, gost_name)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ PDF —Ñ–∞–π–ª–∞: {e}")
        import traceback

        traceback.print_exc()
        return {"success": False, "error": str(e)}


def analyze_document_with_images(file_path: str, gost_name: str) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —á–µ—Ä–µ–∑ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    try:
        print(f"üñºÔ∏è –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {file_path}")

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        images, base64_images = doc_processor.process_document(file_path)
        print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω –≤ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

        if not base64_images:
            return {
                "success": False,
                "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
            }

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞ –ø–æ –ì–û–°–¢—É
        if "7.32" in gost_name:
            return analyze_structure_from_images(base64_images, gost_name)
        else:
            return analyze_bibliography_from_images(base64_images, gost_name)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        import traceback

        traceback.print_exc()
        return {"success": False, "error": str(e)}


def analyze_structure_from_pdf(pdf_file_path: str, gost_name: str) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ PDF —Ñ–∞–π–ª—É (–ì–û–°–¢ 7.32-2001)."""
    system_instruction = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –Ω–∞—É—á–Ω—ã—Ö —Ä–∞–±–æ—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢ 7.32-2001. 
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π PDF –¥–æ–∫—É–º–µ–Ω—Ç –∏ –ø—Ä–æ–≤–µ—Ä—è–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ. 
–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ markdown —Ä–∞–∑–º–µ—Ç–∫–∏."""

    prompt = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π PDF –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ì–û–°–¢ 7.32-2001. 
–í–µ—Ä–Ω–∏ JSON —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞, —Ç–∏—Ç—É–ª—å–Ω–æ–≥–æ –ª–∏—Å—Ç–∞, —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è, –≤–≤–µ–¥–µ–Ω–∏—è, –æ—Å–Ω–æ–≤–Ω–æ–π —á–∞—Å—Ç–∏, –∑–∞–∫–ª—é—á–µ–Ω–∏—è –∏ —Å–ø–∏—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã."""

    try:
        response_text = call_ollama_api_with_pdf(
            prompt, system_instruction, pdf_file_path
        )
        cleaned_response = clean_json_response(response_text)
        result = json.loads(cleaned_response)

        result.setdefault("success", True)
        result.setdefault("structure_analysis", {})
        result.setdefault(
            "overall_compliance", {"score": 0, "level": "–Ω–∏–∑–∫–∏–π", "summary": ""}
        )
        result.setdefault("missing_elements", [])
        result.setdefault("general_recommendations", [])

        return result

    except json.JSONDecodeError as e:
        return {
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}",
            "raw_response": response_text[:2000] if "response_text" in locals() else "",
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


def analyze_bibliography_from_pdf(pdf_file_path: str, gost_name: str) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏ –ø–æ PDF —Ñ–∞–π–ª—É (–ì–û–°–¢ –† 7.0.5-2008)."""
    system_instruction = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–º—É –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢ –† 7.0.5-2008. 
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π PDF –¥–æ–∫—É–º–µ–Ω—Ç –∏ –Ω–∞—Ö–æ–¥–∏ –≤—Å–µ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏. 
–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ markdown —Ä–∞–∑–º–µ—Ç–∫–∏."""

    prompt = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π PDF –¥–æ–∫—É–º–µ–Ω—Ç –∏ –Ω–∞–π–¥–∏ –≤—Å–µ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏. 
–ü—Ä–æ–≤–µ—Ä—å –∫–∞–∂–¥—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ì–û–°–¢ –† 7.0.5-2008 –∏ –≤–µ—Ä–Ω–∏ JSON —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""

    try:
        response_text = call_ollama_api_with_pdf(
            prompt, system_instruction, pdf_file_path
        )
        cleaned_response = clean_json_response(response_text)
        result = json.loads(cleaned_response)

        result.setdefault("success", True)
        result.setdefault("total_found", 0)
        result.setdefault("correct_count", len(result.get("correct_references", [])))
        result.setdefault(
            "incorrect_count", len(result.get("incorrect_references", []))
        )
        result.setdefault("correct_references", [])
        result.setdefault("incorrect_references", [])
        result.setdefault("general_recommendations", [])

        if result["total_found"] == 0:
            result["total_found"] = result["correct_count"] + result["incorrect_count"]

        return result

    except json.JSONDecodeError as e:
        return {
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}",
            "raw_response": response_text[:2000] if "response_text" in locals() else "",
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


def analyze_structure_from_images(images_base64: List[str], gost_name: str) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º (–ì–û–°–¢ 7.32-2001)."""
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç—ã –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏–ª–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–¥–µ—Å—å
    # –î–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â—ë–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
    system_instruction = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –Ω–∞—É—á–Ω—ã—Ö —Ä–∞–±–æ—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢ 7.32-2001. 
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –ø—Ä–æ–≤–µ—Ä—è–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ. 
–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ markdown —Ä–∞–∑–º–µ—Ç–∫–∏."""

    prompt = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ì–û–°–¢ 7.32-2001. 
–í–µ—Ä–Ω–∏ JSON —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞, —Ç–∏—Ç—É–ª—å–Ω–æ–≥–æ –ª–∏—Å—Ç–∞, —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è, –≤–≤–µ–¥–µ–Ω–∏—è, –æ—Å–Ω–æ–≤–Ω–æ–π —á–∞—Å—Ç–∏, –∑–∞–∫–ª—é—á–µ–Ω–∏—è –∏ —Å–ø–∏—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã."""

    try:
        response_text = call_ollama_api_with_images(
            prompt, system_instruction, [images_base64[0]]
        )
        cleaned_response = clean_json_response(response_text)
        result = json.loads(cleaned_response)

        result.setdefault("success", True)
        result.setdefault("structure_analysis", {})
        result.setdefault(
            "overall_compliance", {"score": 0, "level": "–Ω–∏–∑–∫–∏–π", "summary": ""}
        )
        result.setdefault("missing_elements", [])
        result.setdefault("general_recommendations", [])

        return result

    except json.JSONDecodeError as e:
        return {
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}",
            "raw_response": response_text[:2000] if "response_text" in locals() else "",
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


def analyze_bibliography_from_images(images_base64: List[str], gost_name: str) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º (–ì–û–°–¢ –† 7.0.5-2008)."""
    system_instruction = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–º—É –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢ –† 7.0.5-2008. 
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –Ω–∞—Ö–æ–¥–∏ –≤—Å–µ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏. 
–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ markdown —Ä–∞–∑–º–µ—Ç–∫–∏."""

    prompt = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –Ω–∞–π–¥–∏ –≤—Å–µ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏. 
–ü—Ä–æ–≤–µ—Ä—å –∫–∞–∂–¥—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ì–û–°–¢ –† 7.0.5-2008 –∏ –≤–µ—Ä–Ω–∏ JSON —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""

    try:
        response_text = call_ollama_api_with_images(
            prompt, system_instruction, images_base64
        )
        cleaned_response = clean_json_response(response_text)
        result = json.loads(cleaned_response)

        result.setdefault("success", True)
        result.setdefault("total_found", 0)
        result.setdefault("correct_count", len(result.get("correct_references", [])))
        result.setdefault(
            "incorrect_count", len(result.get("incorrect_references", []))
        )
        result.setdefault("correct_references", [])
        result.setdefault("incorrect_references", [])
        result.setdefault("general_recommendations", [])

        if result["total_found"] == 0:
            result["total_found"] = result["correct_count"] + result["incorrect_count"]

        return result

    except json.JSONDecodeError as e:
        return {
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞: {e}",
            "raw_response": response_text[:2000] if "response_text" in locals() else "",
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


def analyze_document_with_gost(text_content, gost_name="–ì–û–°–¢ –† 7.0.5-2008"):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∏ –Ω–∞—Ö–æ–¥–∏—Ç –æ—à–∏–±–∫–∏ –≤ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–∫–∞—Ö —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢."""
    # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –ø–æ–ª–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –º–æ–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
    system_instruction = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–º—É –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢ –† 7.0.5-2008."""

    text_for_analysis = text_content[:50000]
    if len(text_content) > 50000:
        print(f"–¢–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω —Å {len(text_content)} –¥–æ 50000 —Å–∏–º–≤–æ–ª–æ–≤")

    prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –Ω–∞–π–¥–∏ –≤—Å–µ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏. 
–ü—Ä–æ–≤–µ—Ä—å –∫–∞–∂–¥—É—é –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ì–û–°–¢ –† 7.0.5-2008.

–¢–ï–ö–°–¢ –î–û–ö–£–ú–ï–ù–¢–ê:
{text_for_analysis}

–í–µ—Ä–Ω–∏ JSON —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏, —Ä–∞–∑–¥–µ–ª–∏–≤ –∏—Ö –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ."""

    try:
        response_text = call_ollama_api(
            prompt, system_instruction, max_output_tokens=8000, temperature=0.1
        )
        cleaned_response = clean_json_response(response_text)
        result = json.loads(cleaned_response)

        result.setdefault("success", True)
        result.setdefault("total_found", 0)
        result.setdefault("correct_count", len(result.get("correct_references", [])))
        result.setdefault(
            "incorrect_count", len(result.get("incorrect_references", []))
        )
        result.setdefault("correct_references", [])
        result.setdefault("incorrect_references", [])
        result.setdefault("general_recommendations", [])
        result.setdefault("error", None)

        if result["total_found"] == 0:
            result["total_found"] = result["correct_count"] + result["incorrect_count"]

        result["processed_count"] = result["total_found"]
        return result

    except json.JSONDecodeError as e:
        return {
            "success": False,
            "total_found": 0,
            "correct_count": 0,
            "incorrect_count": 0,
            "correct_references": [],
            "incorrect_references": [],
            "general_recommendations": [],
            "processed_count": 0,
            "error": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –ò–ò: {str(e)}",
            "raw_response": (
                cleaned_response[:2000] if "cleaned_response" in locals() else ""
            ),
        }
    except Exception as e:
        return {
            "success": False,
            "total_found": 0,
            "correct_count": 0,
            "incorrect_count": 0,
            "correct_references": [],
            "incorrect_references": [],
            "general_recommendations": [],
            "processed_count": 0,
            "error": str(e),
        }


def analyze_document_structure_gost_732(text_content):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ì–û–°–¢ 7.32-2001."""
    system_instruction = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –Ω–∞—É—á–Ω—ã—Ö –∏ —É—á–µ–±–Ω—ã—Ö —Ä–∞–±–æ—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –ì–û–°–¢ 7.32-2001."""

    text_for_analysis = text_content[:50000]
    prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ì–û–°–¢ 7.32-2001.

–¢–ï–ö–°–¢ –î–û–ö–£–ú–ï–ù–¢–ê:
{text_for_analysis}

–í–µ—Ä–Ω–∏ JSON —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞."""

    try:
        response_text = call_ollama_api(
            prompt, system_instruction, max_output_tokens=8000, temperature=0.1
        )
        cleaned_response = clean_json_response(response_text)
        result = json.loads(cleaned_response)

        result.setdefault("success", True)
        result.setdefault("document_type", "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω")
        result.setdefault("structure_analysis", {})
        result.setdefault("formatting_analysis", {})
        result.setdefault(
            "overall_compliance", {"score": 0, "level": "–Ω–∏–∑–∫–∏–π", "summary": ""}
        )
        result.setdefault("missing_elements", [])
        result.setdefault("corrections", [])
        result.setdefault("general_recommendations", [])
        result.setdefault("error", None)

        result["processed_count"] = len(result.get("corrections", []))
        structure = result.get("structure_analysis", {})
        found_count = sum(
            1 for key in structure if structure.get(key, {}).get("present", False)
        )
        result["total_found"] = found_count

        return result

    except json.JSONDecodeError as e:
        return {
            "success": False,
            "document_type": "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω",
            "structure_analysis": {},
            "formatting_analysis": {},
            "overall_compliance": {
                "score": 0,
                "level": "–Ω–∏–∑–∫–∏–π",
                "summary": "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞",
            },
            "missing_elements": [],
            "corrections": [],
            "general_recommendations": [],
            "processed_count": 0,
            "total_found": 0,
            "error": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –ò–ò: {str(e)}",
            "raw_response": (
                cleaned_response[:2000] if "cleaned_response" in locals() else ""
            ),
        }
    except Exception as e:
        return {
            "success": False,
            "document_type": "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω",
            "structure_analysis": {},
            "formatting_analysis": {},
            "overall_compliance": {
                "score": 0,
                "level": "–Ω–∏–∑–∫–∏–π",
                "summary": "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞",
            },
            "missing_elements": [],
            "corrections": [],
            "general_recommendations": [],
            "processed_count": 0,
            "total_found": 0,
            "error": str(e),
        }


def analyze_document(
    file_path: str, text_content: str, gost_id: int, db_session
) -> dict:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    –í—ã–±–∏—Ä–∞–µ—Ç –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ –∏ –ì–û–°–¢–∞.
    –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ—Ç –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑.
    """
    from database import GOST

    gost = (
        db_session.query(GOST).filter_by(id=gost_id).one_or_none() if gost_id else None
    )
    gost_name = gost.name if gost else "–ì–û–°–¢ –† 7.0.5-2008"

    file_ext = os.path.splitext(file_path)[1].lower()

    # –î–ª—è PDF –ø—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ –ø—Ä—è–º–æ–π –∞–Ω–∞–ª–∏–∑ PDF —Ñ–∞–π–ª–∞, –∑–∞—Ç–µ–º —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if file_ext == ".pdf" and PYMUPDF_AVAILABLE:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å PDF –Ω–∞–ø—Ä—è–º—É—é (–±—ã—Å—Ç—Ä–µ–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ)
        try:
            print(f"üìÑ –ü—Ä–æ–±—É–µ–º –∞–Ω–∞–ª–∏–∑ PDF —Ñ–∞–π–ª–∞ –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è {file_ext}")
            result = analyze_document_with_pdf(file_path, gost_name)
            if result.get("success"):
                print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ PDF —Ñ–∞–π–ª–∞ –Ω–∞–ø—Ä—è–º—É—é —É—Å–ø–µ—à–µ–Ω")
                return result
            print(f"‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ PDF –Ω–∞–ø—Ä—è–º—É—é –Ω–µ —É–¥–∞–ª—Å—è, –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ PDF –Ω–∞–ø—Ä—è–º—É—é: {e}, –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")

        # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç - –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        try:
            print(f"üñºÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è {file_ext}")
            result = analyze_document_with_images(file_path, gost_name)
            if result.get("success"):
                return result
            print(f"‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ —É–¥–∞–ª—Å—è, –ø—Ä–æ–±—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑...")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")

    # –î–ª—è DOCX –ø—Ä–æ–±—É–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    elif file_ext in [".docx", ".doc"] and PYMUPDF_AVAILABLE:
        try:
            print(f"üñºÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è {file_ext}")
            result = analyze_document_with_images(file_path, gost_name)
            if result.get("success"):
                return result
            print(f"‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ —É–¥–∞–ª—Å—è, –ø—Ä–æ–±—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑...")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")

    # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç - —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
    print(f"üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑")
    if "7.32" in gost_name:
        return analyze_document_structure_gost_732(text_content)
    else:
        return analyze_document_with_gost(text_content, gost_name)
